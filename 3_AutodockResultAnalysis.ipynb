{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2971c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36132/36132 [00:22<00:00, 1626.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def parse_xml_binding_energy(xml_file):\n",
    "    \"\"\"\n",
    "    Parse an AutoDock-GPU XML file and compute the average binding energy\n",
    "    from the <rmsd_table> runs.\n",
    "    \n",
    "    Returns:\n",
    "       receptor_code (str): Receptor code extracted from the XML filename.\n",
    "       ligand_code (str): Ligand code extracted from the XML filename.\n",
    "       avg_energy (float): Average binding energy from all <run> entries in the RMSD table.\n",
    "         Returns (None, None, None) if parsing fails or required data is missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Use the XML file's own name to obtain receptor and ligand codes.\n",
    "        base_name = os.path.splitext(os.path.basename(xml_file))[0]  # e.g., \"3ert_lig09685\"\n",
    "        parts = base_name.split(\"_\")\n",
    "        if len(parts) < 2:\n",
    "            print(f\"Warning: Unexpected filename format in {xml_file}\")\n",
    "            return None, None, None\n",
    "        receptor_code = parts[0]\n",
    "        ligand_code = parts[1]\n",
    "        \n",
    "        # Find the <result> element and the <rmsd_table> within it.\n",
    "        result_elem = root.find(\"result\")\n",
    "        if result_elem is None:\n",
    "            print(f\"Warning: No <result> section in {xml_file}\")\n",
    "            return receptor_code, ligand_code, None\n",
    "        \n",
    "        rmsd_table_elem = result_elem.find(\"rmsd_table\")\n",
    "        if rmsd_table_elem is None:\n",
    "            print(f\"Warning: No <rmsd_table> element in {xml_file}\")\n",
    "            return receptor_code, ligand_code, None\n",
    "        \n",
    "        energies = []\n",
    "        for run in rmsd_table_elem.findall(\"run\"):\n",
    "            binding_energy = run.get(\"binding_energy\")\n",
    "            if binding_energy is None:\n",
    "                raise ValueError(f\"Missing binding energy in {xml_file}\")\n",
    "            try:\n",
    "                energy = float(binding_energy)\n",
    "                energies.append(energy)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Invalid binding energy value in {xml_file}: {binding_energy}\")\n",
    "            \n",
    "            if len(energies) > 3:\n",
    "                break\n",
    "        \n",
    "        if not energies:\n",
    "            return receptor_code, ligand_code, None\n",
    "        \n",
    "        avg_energy = statistics.mean(energies)\n",
    "        return receptor_code, ligand_code, avg_energy\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing {xml_file}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Set the directory containing the XML files\n",
    "input_dir = os.path.join(\"AutodockGPU\", \"adgpu_output\")  # adjust as needed\n",
    "xml_pattern = os.path.join(input_dir, \"*.xml\")\n",
    "xml_files = glob.glob(xml_pattern)\n",
    "\n",
    "if not xml_files:\n",
    "    print(f\"No XML files found in {input_dir}\")\n",
    "\n",
    "# Dictionary to accumulate energies per receptor-ligand pair.\n",
    "# Structure: results[ligand_code][receptor_code] = list of energies\n",
    "results = {}\n",
    "\n",
    "for xml_file in tqdm(xml_files):\n",
    "    receptor, ligand, avg_energy = parse_xml_binding_energy(xml_file)\n",
    "    if receptor is None or ligand is None or avg_energy is None:\n",
    "        continue\n",
    "    if ligand not in results:\n",
    "        results[ligand] = {}\n",
    "    if receptor not in results[ligand]:\n",
    "        results[ligand][receptor] = []\n",
    "    results[ligand][receptor].append(avg_energy)\n",
    "\n",
    "# Compute the final mean energy for each receptor-ligand pair.\n",
    "final_data = []\n",
    "for ligand_code, receptor_dict in results.items():\n",
    "    for receptor_code, energy_list in receptor_dict.items():\n",
    "        if energy_list:\n",
    "            final_avg = statistics.mean(energy_list)\n",
    "            final_data.append({\n",
    "                \"Ligand\": ligand_code,\n",
    "                \"Receptor\": receptor_code,\n",
    "                \"Binding Energy\": final_avg\n",
    "            })\n",
    "            # print(f\"Ligand {ligand_code}, Receptor {receptor_code}: energies = {energy_list} -> Mean = {final_avg:.2f} kcal/mol\")\n",
    "\n",
    "# Create a DataFrame from the final data.\n",
    "df = pd.DataFrame(final_data)\n",
    "\n",
    "if not df.empty:\n",
    "    # Pivot the DataFrame: rows are ligand codes; columns are receptor codes.\n",
    "    df_pivot = df.pivot(index=\"Ligand\", columns=\"Receptor\", values=\"Binding Energy\")\n",
    "    df_pivot.sort_index(inplace=True)\n",
    "    df_pivot = df_pivot[sorted(df_pivot.columns)]\n",
    "    \n",
    "    # Now, map receptor codes to receptor names by scanning the receptor folder.\n",
    "    receptor_dir = \"AutodockGPU/receptor\"\n",
    "    receptor_mapping = {}\n",
    "    \n",
    "    if os.path.exists(receptor_dir):\n",
    "        for folder in os.listdir(receptor_dir):\n",
    "            folder_path = os.path.join(receptor_dir, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                parts = folder.split(\"_\")\n",
    "                if len(parts) >= 2:\n",
    "                    code = parts[0]\n",
    "                    receptor_name = parts[1].upper()  # e.g. convert \"pparg\" to \"PPARG\"\n",
    "                    receptor_mapping[code] = receptor_name\n",
    "                else:\n",
    "                    print(f\"Warning: unexpected receptor folder name format: {folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: receptor directory {receptor_dir} not found.\")\n",
    "    \n",
    "    # Rename DataFrame columns using the receptor mapping.\n",
    "    df_pivot.rename(columns=receptor_mapping, inplace=True)\n",
    "    \n",
    "else:\n",
    "    print(\"No binding energy data was extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22314467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████| 36132/36132 [00:39<00:00, 903.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of columns for each receptor:\n",
      "FXR: 56\n",
      "LXRA: 50\n",
      "LXRB: 45\n",
      "PPARA: 57\n",
      "PPARD: 58\n",
      "PPARG: 55\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def get_receptor_mapping(receptor_dir=\"AutodockGPU/receptor\"):\n",
    "    \"\"\"\n",
    "    Scan the receptor directory for folders and build a mapping:\n",
    "       receptor_code -> receptor_name (converted to uppercase)\n",
    "    \"\"\"\n",
    "    receptor_mapping = {}\n",
    "    if os.path.exists(receptor_dir):\n",
    "        for folder in os.listdir(receptor_dir):\n",
    "            folder_path = os.path.join(receptor_dir, folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                parts = folder.split(\"_\")\n",
    "                if len(parts) >= 2:\n",
    "                    code = parts[0]\n",
    "                    receptor_name = parts[1].upper()\n",
    "                    receptor_mapping[code] = receptor_name\n",
    "                else:\n",
    "                    print(f\"Warning: unexpected receptor folder name format: {folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: receptor directory {receptor_dir} not found.\")\n",
    "    return receptor_mapping\n",
    "\n",
    "def parse_xml_contact_info(xml_file, receptor_mapping):\n",
    "    \"\"\"\n",
    "    Parse an AutoDock-GPU XML file to extract contact analysis information.\n",
    "    Compute each run’s weight as -free_NRG_binding, normalize weights to sum=1,\n",
    "    then compute for each contact key the sum of normalized weights of runs\n",
    "    where that contact appears.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing {xml_file}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Filename → receptor_code, ligand_code\n",
    "    base_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "    parts = base_name.split(\"_\")\n",
    "    if len(parts) < 2:\n",
    "        print(f\"Warning: Unexpected filename format in {xml_file}\")\n",
    "        return None, None, None\n",
    "    receptor_code = parts[0]\n",
    "    ligand_code = parts[1]\n",
    "    converted_receptor_name = receptor_mapping.get(receptor_code, receptor_code)\n",
    "\n",
    "    runs_data = []\n",
    "    for run in root.findall(\"runs/run\"):\n",
    "        free_elem = run.find(\"free_NRG_binding\")\n",
    "        if free_elem is None or free_elem.text is None:\n",
    "            continue\n",
    "        try:\n",
    "            free_nrg = float(free_elem.text.strip())\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        contact_analysis = run.find(\"contact_analysis\")\n",
    "        if contact_analysis is None:\n",
    "            continue\n",
    "        res_elem = contact_analysis.find(\"contact_analysis_residue\")\n",
    "        rid_elem = contact_analysis.find(\"contact_analysis_resid\")\n",
    "        if res_elem is None or rid_elem is None or res_elem.text is None or rid_elem.text is None:\n",
    "            continue\n",
    "\n",
    "        residues = [x.strip().strip('\"') for x in res_elem.text.split(\",\") if x.strip()]\n",
    "        resids   = [x.strip().strip('\"') for x in rid_elem.text.split(\",\") if x.strip()]\n",
    "        if len(residues) != len(resids):\n",
    "            print(f\"Warning: Mismatched lengths in {xml_file} run id {run.get('id')}\")\n",
    "            continue\n",
    "\n",
    "        keys = { f\"{converted_receptor_name}_{rid}_{res}\"\n",
    "                 for res, rid in zip(residues, resids) }\n",
    "        runs_data.append({\"contact_keys\": keys, \"free_nrg\": free_nrg})\n",
    "\n",
    "    if not runs_data:\n",
    "        return receptor_code, ligand_code, {}\n",
    "\n",
    "    # Compute raw weights = -free_nrg (so more negative free_nrg → larger positive weight)\n",
    "    for d in runs_data:\n",
    "        d[\"weight\"] = -d[\"free_nrg\"]\n",
    "\n",
    "    # Normalize so sum(weights) = 1\n",
    "    total = sum(d[\"weight\"] for d in runs_data)\n",
    "    if total <= 0:\n",
    "        # fallback to equal weights if something went wrong\n",
    "        n = len(runs_data)\n",
    "        for d in runs_data:\n",
    "            d[\"weight_norm\"] = 1.0 / n\n",
    "    else:\n",
    "        for d in runs_data:\n",
    "            d[\"weight_norm\"] = d[\"weight\"] / total\n",
    "\n",
    "    # Build the set of all contact keys seen across runs\n",
    "    all_keys = set().union(*(d[\"contact_keys\"] for d in runs_data))\n",
    "\n",
    "    # For each key, the weighted average indicator is just the sum of normalized weights\n",
    "    # of runs where that key appears.\n",
    "    contact_avg = {}\n",
    "    for key in all_keys:\n",
    "        contact_avg[key] = sum(d[\"weight_norm\"] for d in runs_data if key in d[\"contact_keys\"])\n",
    "\n",
    "    return receptor_code, ligand_code, contact_avg\n",
    "\n",
    "# Build receptor mapping\n",
    "receptor_mapping = get_receptor_mapping()\n",
    "\n",
    "# Gather XML files\n",
    "input_dir = \"AutodockGPU/adgpu_output\"\n",
    "xml_files = glob.glob(os.path.join(input_dir, \"*.xml\"))\n",
    "if not xml_files:\n",
    "    print(f\"No XML files found in {input_dir}\")\n",
    "\n",
    "# Parse and accumulate per‐ligand\n",
    "ligand_contact_results = {}\n",
    "for xml_file in tqdm(xml_files, desc=\"Processing XML files\"):\n",
    "    receptor, ligand, contact_avg = parse_xml_contact_info(xml_file, receptor_mapping)\n",
    "    if receptor is None or ligand is None or contact_avg is None:\n",
    "        raise ValueError(f\"Failed to parse contact info from {xml_file}\")\n",
    "    ligand_contact_results.setdefault(ligand, []).append(contact_avg)\n",
    "\n",
    "# Combine across files: simple average of each contact key across all XMLs for that ligand\n",
    "final_results = {}\n",
    "for ligand, dicts in ligand_contact_results.items():\n",
    "    concat_dict = {}\n",
    "    for d in dicts:\n",
    "        for key, val in d.items():\n",
    "            assert key not in concat_dict, f\"Duplicate key {key} found in ligand {ligand}\"\n",
    "            concat_dict[key] = val\n",
    "    final_results[ligand] = concat_dict\n",
    "\n",
    "# Make DataFrame: rows=ligand, cols=contact keys\n",
    "all_keys = sorted({k for d in final_results.values() for k in d})\n",
    "df_contact = pd.DataFrame(index=sorted(final_results), columns=all_keys, dtype=float)\n",
    "for ligand, avg_dict in final_results.items():\n",
    "    for key in all_keys:\n",
    "        df_contact.at[ligand, key] = avg_dict.get(key, 0.0)\n",
    "\n",
    "# Count columns per receptor\n",
    "receptor_counts = Counter(col.split(\"_\")[0] for col in df_contact.columns)\n",
    "print(\"\\nNumber of columns for each receptor:\")\n",
    "for receptor, cnt in sorted(receptor_counts.items()):\n",
    "    print(f\"{receptor}: {cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d77b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPARD</th>\n",
       "      <th>LXRA</th>\n",
       "      <th>LXRB</th>\n",
       "      <th>FXR</th>\n",
       "      <th>PPARA</th>\n",
       "      <th>PPARG</th>\n",
       "      <th>FXR_264_TYR</th>\n",
       "      <th>FXR_265_ASN</th>\n",
       "      <th>FXR_266_LYS</th>\n",
       "      <th>FXR_267_GLN</th>\n",
       "      <th>...</th>\n",
       "      <th>PPARG_367_LYS</th>\n",
       "      <th>PPARG_370_PHE</th>\n",
       "      <th>PPARG_371_ALA</th>\n",
       "      <th>PPARG_442_LEU</th>\n",
       "      <th>PPARG_445_ILE</th>\n",
       "      <th>PPARG_449_HIS</th>\n",
       "      <th>PPARG_453_LEU</th>\n",
       "      <th>PPARG_465_LEU</th>\n",
       "      <th>PPARG_469_LEU</th>\n",
       "      <th>PPARG_473_TYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lig0001</th>\n",
       "      <td>1.567212</td>\n",
       "      <td>1.708113</td>\n",
       "      <td>1.436288</td>\n",
       "      <td>1.239629</td>\n",
       "      <td>1.467207</td>\n",
       "      <td>1.482036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig0003</th>\n",
       "      <td>1.078180</td>\n",
       "      <td>1.216345</td>\n",
       "      <td>0.991128</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>1.167743</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig0004</th>\n",
       "      <td>1.315331</td>\n",
       "      <td>1.662367</td>\n",
       "      <td>1.551168</td>\n",
       "      <td>1.268706</td>\n",
       "      <td>1.585744</td>\n",
       "      <td>1.599773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>0.950922</td>\n",
       "      <td>0.950922</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig0006</th>\n",
       "      <td>1.873593</td>\n",
       "      <td>2.085517</td>\n",
       "      <td>1.967608</td>\n",
       "      <td>1.745569</td>\n",
       "      <td>2.059896</td>\n",
       "      <td>1.949713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603522</td>\n",
       "      <td>0.603522</td>\n",
       "      <td>0.603522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig0007</th>\n",
       "      <td>1.272615</td>\n",
       "      <td>1.339287</td>\n",
       "      <td>1.078594</td>\n",
       "      <td>0.778759</td>\n",
       "      <td>1.359587</td>\n",
       "      <td>1.048698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig7531</th>\n",
       "      <td>0.201753</td>\n",
       "      <td>0.324301</td>\n",
       "      <td>0.189579</td>\n",
       "      <td>0.486536</td>\n",
       "      <td>0.422202</td>\n",
       "      <td>0.191835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101518</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>0.329537</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig7532</th>\n",
       "      <td>0.888165</td>\n",
       "      <td>1.064812</td>\n",
       "      <td>0.891914</td>\n",
       "      <td>0.871806</td>\n",
       "      <td>1.018011</td>\n",
       "      <td>0.896621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899361</td>\n",
       "      <td>0.899361</td>\n",
       "      <td>0.899361</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig7533</th>\n",
       "      <td>-0.332942</td>\n",
       "      <td>-0.333296</td>\n",
       "      <td>-0.282996</td>\n",
       "      <td>-0.441019</td>\n",
       "      <td>-0.713266</td>\n",
       "      <td>-0.558738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig7534</th>\n",
       "      <td>-0.321158</td>\n",
       "      <td>-0.487688</td>\n",
       "      <td>-1.068880</td>\n",
       "      <td>-0.752143</td>\n",
       "      <td>-0.335816</td>\n",
       "      <td>-0.499870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lig7535</th>\n",
       "      <td>0.471309</td>\n",
       "      <td>0.252823</td>\n",
       "      <td>0.421950</td>\n",
       "      <td>0.095451</td>\n",
       "      <td>0.238156</td>\n",
       "      <td>0.242527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649059</td>\n",
       "      <td>0.599185</td>\n",
       "      <td>0.850464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6022 rows × 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PPARD      LXRA      LXRB       FXR     PPARA     PPARG  \\\n",
       "lig0001  1.567212  1.708113  1.436288  1.239629  1.467207  1.482036   \n",
       "lig0003  1.078180  1.216345  0.991128  0.713336  1.167743  0.994735   \n",
       "lig0004  1.315331  1.662367  1.551168  1.268706  1.585744  1.599773   \n",
       "lig0006  1.873593  2.085517  1.967608  1.745569  2.059896  1.949713   \n",
       "lig0007  1.272615  1.339287  1.078594  0.778759  1.359587  1.048698   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "lig7531  0.201753  0.324301  0.189579  0.486536  0.422202  0.191835   \n",
       "lig7532  0.888165  1.064812  0.891914  0.871806  1.018011  0.896621   \n",
       "lig7533 -0.332942 -0.333296 -0.282996 -0.441019 -0.713266 -0.558738   \n",
       "lig7534 -0.321158 -0.487688 -1.068880 -0.752143 -0.335816 -0.499870   \n",
       "lig7535  0.471309  0.252823  0.421950  0.095451  0.238156  0.242527   \n",
       "\n",
       "         FXR_264_TYR  FXR_265_ASN  FXR_266_LYS  FXR_267_GLN  ...  \\\n",
       "lig0001          0.0          0.0          0.0          0.0  ...   \n",
       "lig0003          0.0          0.0          0.0          0.0  ...   \n",
       "lig0004          0.0          0.0          0.0          0.0  ...   \n",
       "lig0006          0.0          0.0          0.0          0.0  ...   \n",
       "lig0007          0.0          0.0          0.0          0.0  ...   \n",
       "...              ...          ...          ...          ...  ...   \n",
       "lig7531          0.0          0.0          0.0          0.0  ...   \n",
       "lig7532          0.0          0.0          0.0          0.0  ...   \n",
       "lig7533          0.0          0.0          0.0          0.0  ...   \n",
       "lig7534          0.0          0.0          0.0          0.0  ...   \n",
       "lig7535          0.0          0.0          0.0          0.0  ...   \n",
       "\n",
       "         PPARG_367_LYS  PPARG_370_PHE  PPARG_371_ALA  PPARG_442_LEU  \\\n",
       "lig0001       0.000000       0.000000       0.000000            0.0   \n",
       "lig0003       0.000000       0.000000       0.000000            0.0   \n",
       "lig0004       0.000000       0.000000       0.000000            0.0   \n",
       "lig0006       0.603522       0.603522       0.603522            0.0   \n",
       "lig0007       0.000000       0.000000       0.000000            0.0   \n",
       "...                ...            ...            ...            ...   \n",
       "lig7531       0.284516       0.000000       0.000000            0.0   \n",
       "lig7532       0.000000       0.000000       0.000000            0.0   \n",
       "lig7533       0.000000       0.000000       0.000000            0.0   \n",
       "lig7534       0.000000       0.000000       0.000000            0.0   \n",
       "lig7535       0.349293       0.000000       0.000000            0.0   \n",
       "\n",
       "         PPARG_445_ILE  PPARG_449_HIS  PPARG_453_LEU  PPARG_465_LEU  \\\n",
       "lig0001       0.000000       0.000000       1.000000       0.000000   \n",
       "lig0003       0.000000       1.000000       1.000000       0.000000   \n",
       "lig0004       0.000000       0.049078       0.950922       0.950922   \n",
       "lig0006       0.603522       0.000000       0.000000       0.000000   \n",
       "lig0007       0.000000       1.000000       1.000000       0.048144   \n",
       "...                ...            ...            ...            ...   \n",
       "lig7531       0.000000       1.000000       0.101518       0.050406   \n",
       "lig7532       0.000000       1.000000       0.899361       0.899361   \n",
       "lig7533       0.000000       0.000000       1.000000       1.000000   \n",
       "lig7534       0.000000       0.000000       0.000000       0.000000   \n",
       "lig7535       0.000000       0.649059       0.599185       0.850464   \n",
       "\n",
       "         PPARG_469_LEU  PPARG_473_TYR  \n",
       "lig0001       1.000000            1.0  \n",
       "lig0003       1.000000            1.0  \n",
       "lig0004       0.098698            1.0  \n",
       "lig0006       0.000000            0.0  \n",
       "lig0007       1.000000            1.0  \n",
       "...                ...            ...  \n",
       "lig7531       0.329537            1.0  \n",
       "lig7532       0.899361            1.0  \n",
       "lig7533       1.000000            1.0  \n",
       "lig7534       0.000000            0.0  \n",
       "lig7535       1.000000            1.0  \n",
       "\n",
       "[6022 rows x 327 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_z = df_pivot.copy()\n",
    "for col in df_pivot_z.columns:\n",
    "    mean = df_pivot_z[col].mean()\n",
    "    std = df_pivot_z[col].std()\n",
    "    df_pivot_z[col] = (df_pivot_z[col] - mean) / std\n",
    "    \n",
    "if not df_pivot_z.index.equals(df_contact.index):\n",
    "    raise ValueError(\"Index mismatch between df_pivot_z and df_contact.\")\n",
    "\n",
    "df_concat = pd.concat([df_pivot_z, df_contact], axis = 1)\n",
    "df_concat = df_concat.sort_index(axis=0)\n",
    "\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32782e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save `df_concat` using joblib\n",
    "\n",
    "import joblib\n",
    "\n",
    "# make joblibdata directory if it doesn't exist\n",
    "os.makedirs(\"joblibdata\", exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to a file using joblib\n",
    "file_path = os.path.join(\"joblibdata\", \"docking_result_dataframe.joblib\")\n",
    "joblib.dump(df_concat, file_path)\n",
    "\n",
    "df_concat.to_excel(\"docking_result.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
